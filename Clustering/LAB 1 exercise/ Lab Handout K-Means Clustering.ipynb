{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f341669-1fe9-4d1e-8a51-4e4dbe087058",
   "metadata": {},
   "source": [
    "# üß™ Lab Handout: K-Means Clustering\n",
    "---\n",
    "\n",
    "**Learning Objectives**:\n",
    "\n",
    "- Understand the steps of K-Means clustering\n",
    "\n",
    "- How the **Elbow Method** and **Silhouette Score** are used to find the optimal `k`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608447d9-4a45-47e6-8aa4-9e25105c4447",
   "metadata": {},
   "source": [
    "## üß© K-Means Clustering\n",
    "\n",
    "**K-means clustering** is a method to group data into clusters where each piece of data is closest to the central point, or **centroid**, of its cluster.\n",
    "\n",
    "### Steps of the K-Means Algorithm\n",
    "1. Start with **K centroids** by putting them at random places.  \n",
    "   Example: here K = 2 (randomly selected centroids).  \n",
    "2. Compute the **distance** of every point from each centroid and cluster them accordingly.  \n",
    "3. Adjust centroids so that they become the **center of gravity** for their respective clusters.  \n",
    "4. Re-cluster every point based on their updated distance from the centroids.  \n",
    "5. Again, adjust centroids.  \n",
    "6. Repeat steps until **data points stop changing clusters** (convergence).\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ **SSE** ‚Äì Sum of Squared Errors or **WCSS** - Within Clusters Sum of Square\n",
    "To find the **optimal number of clusters (K)** using SSE:\n",
    "- Plot the **sum of squared distances** from each data point to its cluster‚Äôs centroid.  \n",
    "- Then, select **K** where the decrease in SSE starts to **level off**, known as the **‚Äúelbow point.‚Äù**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c3b33-d720-4505-aeac-f0510438af65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f55420-3137-42a3-8102-3c3c5fbb36d8",
   "metadata": {},
   "source": [
    "## [scikit-learn KMeans Reference](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "**from sklearn.cluster import KMeans**\n",
    "\n",
    "### ‚öôÔ∏è Key Parameters of `KMeans`\n",
    "\n",
    "| Parameter | Description |\n",
    "|------------|-------------|\n",
    "| **n_clusters** | Number of clusters (K) to form. |\n",
    "| **init** | Method for initializing centroids ‚Äî `'k-means++'` *(default)* or `'random'`or manually provide an array of centroids |\n",
    "| **n_init** | Number of times the algorithm runs with different centroid seeds (best result kept). |\n",
    "| **max_iter** | Maximum number of iterations for a single run. |\n",
    "| **random_state** | Controls random number generation for reproducibility. |\n",
    "---\n",
    "\n",
    "### üß© Main Methods\n",
    "\n",
    "| Method | Description |\n",
    "|---------|-------------|\n",
    "| **fit(X)** | Compute K-Means clustering on dataset `X`. |\n",
    "| **fit_predict(X)** | Fit model and return cluster labels for each data point. |\n",
    "| **predict(X)** | Assign new samples to the nearest existing cluster centroid. |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Important Attributes\n",
    "\n",
    "| Attribute | Description |\n",
    "|------------|-------------|\n",
    "| **cluster_centers_** | Coordinates of the cluster centroids. |\n",
    "| **labels_** | Index (0, 1, 2, ‚Ä¶) of the cluster each data point belongs to. |\n",
    "| **inertia_** | Sum of squared distances (SSE) of samples to their nearest centroid. |\n",
    "\n",
    "---\n",
    "\n",
    "üìù **Note:**  \n",
    "- Always scale your data (e.g., using `StandardScaler`) before applying K-Means.  \n",
    "- Choose an appropriate `K` using the **Elbow Method**.  \n",
    "- K-Means assumes **spherical**, equally sized clusters and is sensitive to **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c56266-8256-42d5-81fe-511b8dca36c8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f4da4-290e-4a02-bedd-9a9974865506",
   "metadata": {},
   "source": [
    "## Elbow Method to determine optimal number of clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57542e-8218-4eda-b5f1-12072b5792c2",
   "metadata": {},
   "source": [
    "The **Elbow Method** helps determine the **optimal number of clusters (K)** in a K-Means model.  \n",
    "It is based on analyzing the **Sum of Squared Errors (SSE)**, also known as **inertia** in scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Concept**\n",
    "\n",
    "- As K increases, the **SSE (inertia)** ‚Äî i.e., the sum of squared distances of samples to their nearest cluster center ‚Äî always **decreases**.  \n",
    "- Initially, this reduction is large, but after a certain K, the improvement slows down.  \n",
    "- The point where the **rate of decrease sharply changes** forms an **‚Äúelbow‚Äù** in the curve ‚Äî this K is usually a good choice.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "The SSE (or inertia) is a measure of how well data points are clustered around their respective centroids. It is calculated as follows:\n",
    "\n",
    "$$ SSE = \\sum_{i=1}^{k} \\sum_{x_j \\in C_i} |x_j - \\mu_i|^2$$\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    "$$\n",
    "C_i : \\text{The } i^{\\text{th}} \\text{ cluster}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_i : \\text{The centroid of cluster } i\n",
    "$$ \n",
    "\n",
    "$$\n",
    "x_j : \\text{The } j^{\\text{th}} \\text{ data point (where } x_j \\in C_i \\text{ if it belongs to cluster } i)\n",
    "$$ \n",
    "\n",
    "$$\n",
    "k : \\text{The total number of clusters}\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\|x_j - \\mu_i\\|^2 : \\text{The squared Euclidean distance between the data point } x_j \\text{ and the centroid } \\mu_i\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
